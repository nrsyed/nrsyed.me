<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <link rel="stylesheet" type="text/css" href="styles/template.css">
    <link rel="stylesheet" type="text/css" href="styles/projects.css">
    <meta charset="utf-8">
    <title>Projects</title>
  </head>
  <body class="dark">
    <div id="main">

      <nav>
        <div>
          <div id="name"></div>
          <ul id="nav-links">
            <li><a href="/">About</a></li>
            <li><a href="/projects.html">Projects</a></li>
            <!-- <li><a href="experience.html">Experience</a></li> -->
            <li><a href="https://nrsyed.com">Blog</a></li>
          </ul>

          <ul id="theme-selectors">
            <li><span id="dark" class="theme-selector selected">Dark</span></li>
            <li><span id="light" class="theme-selector">Light</span></li>
            <li><span id="blue" class="theme-selector">Blue</span></li>
          </ul>
        </div>
      </nav>

      <div id="content">
        <div id="nav-spacer"></div>
        <h1>Projects</h1>

        <p>
        A curated, though not necessarily comprehensive, list of projects
        I've worked on professionally, academically, and on my own time. Click
        on any project to read more about it.
        </p>

        <!-- NEW ROW -->
        <div class="project-row">

          <!-- SVM for vehicle detection -->
          <span id="svm" class="project-card">
            <img src="images/svmhog.jpg"
                 data-src="images/svmhog.jpg"
                 data-hover="images/svmhog.gif" />
            <hr>
            <h4>Dashcam vehicle detection</h4>
          </span>

          <!-- Half-car suspension model -->
          <span id="halfcar" class="project-card">
            <img src="images/halfcar.jpg"
                 data-src="images/halfcar.jpg"
                 data-hover="images/halfcar.gif" />
            <hr>
            <h4>Half-car suspension model</h4>
          </span>

          <!-- Articulating foot platform -->
          <span id="afp" class="project-card">
            <img src="images/afp.jpg"
                 data-src="images/afp.jpg"
                 data-hover="images/afp.gif" />
            <hr>
            <h4>Articulating foot platform</h4>
          </span>
        </div>
        <!-- END ROW -->

        <!-- NEW ROW -->
        <div class="project-row">

          <!-- Portfolio website -->
          <span id="portfolio" class="project-card">
            <img src="images/portfolio-site.jpg"
                 data-src="images/portfolio-site.jpg"
                 data-hover="images/portfolio-site.gif" />
            <hr>
            <h4>Portfolio website</h4>
          </span>

          <!-- K-means for colorblindness tests -->
          <span id="colorblind" class="project-card">
            <img src="images/colorblind.jpg"
                 data-src="images/colorblind.jpg"
                 data-hover="images/colorblind.gif" style="border-radius: 50%" />
            <hr>
            <h5>Machine learning for colorblindness tests</h5>
          </span>

          <!-- Autonomous robot -->
          <span id="588" class="project-card">
            <img src="images/588.jpg"
                 data-src="images/588.jpg"
                 data-hover="images/588.gif" style="" />
            <hr>
            <h4>Autonomous ball-retrieval robot</h4>
          </span>
        </div>
        <!-- END ROW -->

        <!-- NEW ROW -->
        <div class="project-row">

          <!-- Color thresholding -->
          <span id="colorthresh" class="project-card">
            <img src="images/thresh.jpg"
                 data-src="images/thresh.jpg"
                 data-hover="images/thresh.gif" style="border-radius: 2%" />
            <hr>
            <h4>Multichannel color thresholding</h4>
          </span>

          <!-- Robot arm inverse kinematics -->
          <span id="ik" class="project-card">
            <img src="images/ik.jpg"
                 data-src="images/ik.jpg"
                 data-hover="images/ik.gif" style="border-radius: 50%" />
            <hr>
            <h4>Simulated n-DOF robot arm IK</h4>
          </span>

          <!-- Breadth-first path planning -->
          <span id="bfspath" class="project-card">
            <img src="images/path.jpg"
                 data-src="images/path.jpg"
                 data-hover="images/path.gif" />
            <hr>
            <h5>Breadth-first search path planning</h5>
          </span>

        </div>
        <!-- END ROW -->

        <!-- NEW ROW -->
        <div class="project-row">

          <!-- Squat biomechanics -->
          <span id="squat" class="project-card">
            <img src="images/squat.jpg"
                 data-src="images/squat.jpg"
                 data-hover="images/squat.gif" style="" />
            <hr>
            <h4>Biomechanics of the supported squat</h4>
          </span>

          <!-- Wheelchair suspension -->
          <span id="suspension" class="project-card">
            <img src="images/suspension.jpg"
                 data-src="images/suspension.jpg"
                 data-hover="images/suspension.gif" style="" />
            <hr>
            <h5>Indeterminate wheelchair suspension</h5>
          </span>

          <!-- Game of Life -->
          <span id="gameoflife" class="project-card">
            <img src="images/gameoflife.jpg"
                 data-src="images/gameoflife.jpg"
                 data-hover="images/gameoflife.gif" style="" />
            <hr>
            <h5>Dynamic variations on Conway's Game of Life</h5>
          </span>

        </div>
        <!-- END ROW -->

        <!-- NEW ROW -->
        <div class="project-row">

          <!-- Real-time color histogram -->
          <span id="histogram" class="project-card">
            <img src="images/histogram.jpg"
                 data-src="images/histogram.jpg"
                 data-hover="images/histogram.gif" style="" />
            <hr>
            <h4>Real-time color histogram</h4>
          </span>

          <!-- Linear actuator -->
          <span id="actuator" class="project-card">
            <img src="images/actuator.jpg"
                 data-src="images/actuator.jpg"
                 data-hover="images/actuator.gif" style="" />
            <hr>
            <h4>Design of a linear actuator</h4>
          </span>

          <!-- Sorting algos -->
          <span id="sort" class="project-card">
            <img src="images/sort.jpg"
                 data-src="images/sort.jpg"
                 data-hover="images/sort.gif" style="" />
            <hr>
            <h4>Visualizing sorting algorithms</h4>
          </span>

        </div>
        <!-- END ROW -->

        <div id="footer"></div>
        <div id="footer">&copy; 2019 Najam R. Syed</div>
      </div>

      <!-- Modal windows -->
      <div id="svm-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>HOG-based SVM for vehicle detection</h3>
          </div>
          <div class="modal-body">
            <p align="center"><iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/uOxkAF0iA3E"
              frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe></p>
            <p>Read more on
            <a href="https://github.com/nrsyed/svm-vehicle-detector">Github</a>
            or read this
            <a href="https://nrsyed.com/2018/05/06/hog-based-svm-for-detecting-vehicles-in-a-video-part-1/">
              series of posts</a> about the project on my blog.
            </p>
            <p>
            Using OpenCV-Python, scikit-image, and scikit-learn, I extracted
            histogram of oriented gradients (HOG) features, as well as color
            histogram and 2D spatial features, from images of vehicles and
            non-vehicles from the KITTI and GTI datasets to train a linear
            support vector machine (SVM) classifier. To improve the accuracy of
            the classifier, I determined the most effective color space and
            combination of color channels to use for classification, as well as
            the optimal parameters and tolerances for the classifier itself.
            </p>
            <p>
            I employed a sliding window search to find cars in an actual video,
            limiting the search to the region below the horizon and increasing
            the size of the sliding window as as it approached the bottom of the
            frame, since vehicles closer to the bottom are closer to the
            camera and, hence, appear larger.
            </p>
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/6e8XB-bKsZ4" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </p>
            <p>
            This produced a set of detections for any given frame. Actual cars
            (as opposed to false positives) yielded numerous detections.
            </p>
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/TfX6jtuPL0I" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </p>
            <p>
            To determine which regions of the image represented a vehicle
            (and to combine multiple detections of the same object), I computed
            a heatmap of the detections. To reduce the effect of transients in
            any given frame, I summed the heatmaps of the last several frames
            and ignored pixels in the heatmap below a certain threshold.
            </p>
            <p align="center">
              <iframe width="560" height="315"
                src="https://www.youtube-nocookie.com/embed/OT68xGggpkM" frameborder="0"
                allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </p>
            <p>
            Next, I applied simple connected component analysis to the heatmap
            to identify and distinguish individual vehicles.
            </p>
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/iOt_3tQJBFY" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </p>
            <p>
            Finally, I drew bounding boxes around objects larger than some minimum
            size to produce the final video at the beginning of this description.

            While most contemporary object detection schemes utilize neural
            networks, completing this project provided me a better understanding
            of various image recognition techniques, as well as insight
            into both the advantages and shortcomings of SVMs.
            </p>
          </div>
        </div>
      </div>

      <div id="afp-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Articulating foot platform</h3>
          </div>
          <div class="modal-body">
            <img src="images/afp_retracted.jpg">
            <img src="images/afp_extended.jpg">
            <p>
            While working at Quantum Rehab, I was tasked with designing a
            prototype for a new articulating foot platform (AFP), or power
            leg-rest, for use on Quantum power wheelchair TRU-Balance seating
            systems. The current AFP is pictured above, both retracted (top)
            and extended (bottom). The goal was to create a smaller and lighter
            design to reduce the overall weight of the power chair without
            compromising performance.
            </p>
            <p>
            To aid in the design of a new prototype, I first developed a
            kinematic model of the four-bar mechanism utilized by the existing
            model, pictured below.
            </p>
            <img src="images/afp_geometry.jpg">
            <p>
            Furthermore, to quantify the effect of the device on the legs of
            users, I developed a simplified inverse kinematic model of the
            human leg (below).
            </p>
            <img src="images/afp_leg.jpg">
            <p>
            Combining the kinematics of the device and the leg with the weight
            of each component, I developed a dynamic model of the system, with
            the aim of solving for the axial forces acting on the linear
            actuators in the device.
            </p>
            <img src="images/afp_forces.jpg">
            <p>
            I wrote Python scripts to numerically solve for these forces
            over the device's range of motion. To verify the accuracy of the
            model, I performed real-world tests of the AFP under a variety
            of loading conditions. The model correctly predicted the behavior
            of the actual device with &gt;95% accuracy.
            </p>
            <p>
            Having verified the model, I performed sensitivity analysis to
            optimize and modify key parameters of the design, allowing me to
            develop a late-stage prototype that was 25% lighter and 15% slimmer
            than the existing model, and whose range of motion was 10% greater
            than the existing model. Furthermore, since the AFP sits at the
            front of the wheelchair, the weight reduction contributed to the
            stability of the chair by shifting its overall center of gravity
            farther back.
            </p>
          </div>
        </div>
      </div>

      <div id="portfolio-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Portfolio website</h3>
          </div>
          <div class="modal-body">
            <img src="images/site_vim.jpg">
            <p>
            As an exercise in economy and self-education, I developed this site
            from scratch using nothing but HTML, CSS, and plain (vanilla)
            JavaScript&mdash;no frameworks, no libraries, no external
            resources. Every character of source code is my own, for better
            or worse.
            </p>
            <p>
            I also set up and secured the VPS&mdash;a DigitalOcean
            droplet&mdash;on which this site is currently hosted, which involved
            installing and configuring Apache, MySQL, and PHP, among other
            things.
            </p>
          </div>
        </div>
      </div>

      <div id="halfcar-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Half-car suspension model</h3>
          </div>
          <div class="modal-body">
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/_CIp4ywYVUs" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </p>
            <p>
            Read more about this project on
            <a href="https://nrsyed.com/2018/01/07/numerical-approach-to-studying-vehicle-dynamics-with-a-half-car-suspension-model/">
              my blog</a> or on <a href="https://github.com/nrsyed/half-car">
              Github</a>.
            </p>
            <p>
            For this exercise in vehicle dynamics, I numerically solved
            the differential equations of motion of a half-car model
            using the Euler method, then animated the result in Python with 
            matplotlib. A half-car model considers half of a car and treats
            both the suspension and the wheels as springs and dampers.
            </p>
            <img src="images/chassis_accels-768x377.jpg">
            <img src="images/wheel_accels2-768x428.jpg">
            <p>
            This is a 4-DOF system in which the vertical displacement of each
            wheel, the vertical displacement of the chassis, and the pitch angle
            of the chassis may vary.
            </p>
            <p>
            An advantage of numerical solutions, like the Euler method, is that
            they make it relatively easy to solve for the response of the
            system with nonlinear inputs, at the potential cost of stability
            and accuracy.
            </p>
            <p>
            The vehicle outline is that of a 2010 Honda Accord Coupe&mdash;a car
            that's treated me well over the years.
            </p>
            <img src="images/accord_vars-768x561.jpg">
          </div>
        </div>
      </div>

      <div id="colorblind-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>K-means clustering for deciphering colorblindness tests</h3>
          </div>
          <div class="modal-body">
            <img src="images/ishihara_16_comparison.jpg" style="text-align: center">
            <p>
            Read more about the project and the results in
            <a href="https://nrsyed.com/2018/03/25/image-segmentation-via-k-means-clustering-to-decipher-color-blindness-tests/">
              this blog post</a>, check out the code on
            <a href="https://github.com/nrsyed/computer-vision/blob/master/kmeans_color_segmentation/color_segmentation.py">
              Github</a>, or read
            <a href="https://nrsyed.com/2018/03/29/image-segmentation-via-k-means-clustering-with-opencv-python/">
              this blog post</a> discussing the code.
            </p>
            <p>
            Being mildly colorblind myself, I thought it would be interesting
            to utilize K-means clustering, a conventional machine learning
            technique, to distinguish the numbers in Ishihara color blindness
            tests from the backgrounds.
            </p>
            <p>
            I wrote a command-line Python utility that facilitates
            color-based segmentation of an image by converting the
            image to a desired color space (e.g., HSV, Lab, etc.), selecting
            any combination of color channels on which to perform the
            K-means clustering, selecting the number of clusters for the
            algorithm, and writing the output to the disk in the form of an
            image file.
            </p>
            <p>
            Examples of the output of the tool, which utilizes scikit-learn
            and OpenCV, are shown above for one particular Ishihara plate
            using different color spaces, color channels, and numbers of
            clusters.
            </p>
          </div>
        </div>
      </div>

      <div id="588-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Autonomous ball retrieval robot</h3>
          </div>
          <div class="modal-body">
            <img src="images/588_area.jpg">
            <p>
            As part of a mechatronics course at Purdue, I worked with a team to
            develop a small autonomous robot charged with performing the
            following tasks without human intervention:
            </p>
            <ol>
              <li>
                Navigate a walled test area containing several softballs
                (pictured above).
              </li>
              <li>
                Locate and collect the softballs.
              </li>
              <li>
                Find a black line on the floor, follow it to a drop-off point,
                and deposit the softballs.
              </li>
            </ol>
            <p>
            Our design called for infrared distance sensors to detect both the
            softballs and the test area walls, and infrared line-following
            sensors to find and follow the black line. The ball-collection
            mechanism was essentially a "claw" or inverted scoop attached to
            a motor that, with the help of additional motorized rollers,
            coaxed each softball into a channel. An early SolidWorks model of
            the design can be seen below.
            </p>
            <img src="images/588_model.jpg">
            <p> The walls were not attached directly to the floor, but were
            several inches above the floor, as seen below.
            </p>
            <img src="images/588_comp.jpg">
            <p>
            We exploited this fact by placing one set of IR distance sensors
            close to the floor and another set higher up on the robot to
            distinguish walls from softballs. These sensors, as well
            as the ball-collection mechanism, can be seen in the figures below.
            </p>
            <img src="images/588_robot2.jpg">
            <img src="images/588_robot1.jpg">
            <p>
            For control, we developed a finite state machine and wrote code
            in C that was deployed on an Arduino Mega. We also made use of
            existing C++ libraries for tasks related to line following.
            </p>
            <p>
            In the end, the robot was moderately successful, though not without
            its hiccups. If I were to tackle a similar problem again,
            I would likely leverage the ability of a single camera and
            computer vision techniques, perhaps running on a Raspberry Pi,
            to replace the numerous IR sensors.
            <p>
          </div>
        </div>
      </div>

      <div id="colorthresh-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Multichannel color thresholding utility</h3>
          </div>
          <div class="modal-body">
            <p align="center">
              <iframe width="560" height="315"
                src="https://www.youtube-nocookie.com/embed/YGzXznbvyNU"
                frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </p>
            <p>
            Find the code on
            <a href="https://github.com/nrsyed/computer-vision/tree/master/ColorThreshUtil">
              Github</a>.
            </p>
            <p>
            Image segmentation based on color thresholding is relatively
            common in computer vision applications. Color-based object
            tracking is a notable example. However, determining the range
            of color channel values between which a specific object or
            feature falls can be a hassle.
            </p>
            <p>
            Using OpenCV, I wrote a utility to allow a user to rapidly segment
            a video or image by adjusting the lower and upper values for each
            color channel and visualizing the result in real time. I wrote both
            a C++ version of the program and a Python version.
            </p>
          </div>
        </div>
      </div>

      <div id="ik-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Simulated n-DOF robot arm inverse kinematics</h3>
          </div>
          <div class="modal-body">
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/BHzn52bcKIo"
              frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
            </p>
            <p>
            Find the code on
            <a href="https://github.com/nrsyed/examples">Github</a> (in the
            files <code>RobotArm.py</code> and <code>jacobianInverse.py</code>),
            read more about the code and the implementation in
            <a href="https://nrsyed.com/2017/12/17/animating-the-jacobian-inverse-method-with-an-interactive-matplotlib-plot/">
              this blog post</a>, or read more about the mathematics
            and derivation of the Jacobian inverse method in
            <a href="https://nrsyed.com/2017/12/10/inverse-kinematics-using-the-jacobian-inverse-part-1/">
              this series of blog posts</a>.
            </p>
            <p>
            To visualize the Jacobian inverse method for solving the inverse
            kinematics of a system in two dimensions, I wrote a
            Python program that made use of numpy and matplotlib to simulate
            a robot arm consisting of an arbitrary number of linkages
            connected by revolute joints.
            </p>
            <p>
            In the video above, the linkages are represented by green line
            segments, the joints by solid green circles, and the single
            end-effector by a hollow circle. The robot arm is made to track
            a target represented by a red dot. The dashed circle
            represents the maximum reach of the robot arm, based on the sum of
            the lengths of the individual linkages. In the video, this is
            used to demonstrate a limitation of the Jacobian inverse method:
            its instability at singularities, which occurs when all of the
            joints are collinear.
            </p>
            <p>
            The matplotlib plot is interactive and contains two modes. In the
            first mode, the user can click anywhere within the plot to place
            the red dot, after which the robot arm automatically tracks it.
            With a keypress, the user can switch to a second mode in which the
            dot travels along a pseudorandom path, demonstrating the ability
            of the robot arm to track a moving target.
            </p>
          </div>
        </div>
      </div>

      <div id="bfspath-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Breadth-first search path planning</h3>
          </div>
          <div class="modal-body">
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/3ZZLqPVURe8"
              frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
            </p>
            <p>
            Find the code on
            <a href="https://github.com/nrsyed/examples">Github</a> (in the
            files <code>Grassfire.py</code> and <code>animGrassfire.py</code>)
            and read more about the implementation in
            <a href="https://nrsyed.com/2017/12/30/animating-the-grassfire-path-planning-algorithm/">
              this blog post</a>.
            </p>
            <p>
            While learning about graph traversal and graph-based path
            planning methods, I wrote a Python script that utilized an
            interactive matplotlib plot to animate the breadth-first search
            method for finding the shortest path between two points on a grid.
            </p>
            <p>
            As the video above demonstrates, the program randomly places a
            start cell (green), a destination cell (red), and obstacles
            (black), then illustrates the expanding wavefront of visited
            cells with blue. If the destination cell is found, the algorithm
            backtracks to display the shortest path, or one of the
            shortest paths, if multiple solutions exist.
            </p>
            <p>
            The program, being interactive, allows the user to adjust the
            number of grid rows and grid columns, adjust the obstacle density
            (probability that any given cell will be an obstacle), as well as
            randomize the locations of the start cell, destination cell, and
            obstacles.
            </p>
          </div>
        </div>
      </div>

      <div id="squat-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Partial body weight support and squat biomechanics</h3>
          </div>
          <div class="modal-body">
            <p>
              MS thesis title:
              <em>The effect of body weight support on squat biomechanics</em>
              <br>
              <a href="https://docs.lib.purdue.edu/dissertations/AAI10062247/">
                Link to abstract
              </a>
            </p>
            <h4 align="center">Motivation and theory</h4>
            <p>
            My Master's thesis combined robotics and biomechanics, the goal
            being to investigate the effect of providing partial weight support
            on the forces and moments in the ankle, knee, and hip joints.
            </p>
            <p>
            The squat and squat-like motions, such as the sit-to-stand and
            stand-to-sit transitions, are ubiquitous among all people in all
            parts of the world. Partial weight support is often used in
            physiotherapeutic settings for the physical rehabilitation of
            individuals, and assistive or augmentative devices like robotic
            exoskeletons also provide a form of partial weight support.
            While the effect of weight support on fundamental motions like
            walking and running has been well studied, there have
            been few or no studies on how weight support affects the squatting
            motion. My thesis aimed to help fill this gap.
            </p>
            <img src="images/thesis_inverse_dynamics.jpg" style="max-width: 70%">
            <div class="caption">
              Inverse dynamics of the lower limbs.
            </div>
            <p>
            I sought to characterize the effect by quantifying the forces and
            moments in the joints of the lower limb via inverse dynamics, which
            involves measuring the ground reaction force (GRF) and the positions
            of the lower limb segments to back-calculate the reactions in each
            joint based on the position and inertial properties of each limb
            segment. The free body diagrams above illustrate the technique.
            </p>
            <h4 align="center">Experimental setup</h4>
            <img src="images/thesis_setup.jpg">
            <div class="caption">
              A diagram of the setup. The ropes connecting the harness
              to the pneumatic actuators are shown in red.
            </div>
            <p>
            The experimental setup is illustrated in the figure above.
            To measure the ground reaction force, users performed squats on a
            force plate&ndash;instrumented treadmill (the treadmill wasn't
            running&mdash;it was only used for its force plates). Weight support
            was provided by means of a harness connected via ropes to pneumatic
            actuators.
            </p>
            <img src="images/thesis_squat.jpg">
            <div class="caption">
              A user preparing for an experimental trial.
            </div><br>
            <h4 align="center">Data acquisition</h4>
            <img src="images/thesis_vicon_setup.jpg">
            <div class="caption">
              Vicon camera setup for obtaining 3D kinematic data.
            </div>
            <p>
            As mentioned above, ground reaction forces were obtained with
            force plates. The applied force was measured by load cells.
            The user's motion was recorded with Vicon infrared cameras,
            shown in the figure above. The figure below shows the markers, which
            were placed on the subjects' joints and on various points on
            their legs, as seen by the cameras.
            </p>
            <img src="images/thesis_vicon_software.jpg">
            <div class="caption">
              Kinematic data visualized by the Vicon software.
            </div>
            <p>
            The pneumatic actuators were connected to a National Instruments
            cRIO embedded controller. To control the actuators, provide a
            consistent amount of weight support, and automate the data
            acquisition process, I wrote custom LabVIEW VIs and implemented
            a PID control loop, allowing the system to conduct trials on its
            own, informing the user when to prepare for the next set or
            the next repetition, and waiting until the user was ready before
            beginning to apply the desired amount of weight support.
            </p>
            <h4 align="center">Data analysis and results</h4>
            <img src="images/thesis_moments.jpg">
            <div class="caption">
              Representative plot of joint moments, joint angles, and applied
              load (weight support) for a single trial.
            </div>
            <p>
            To process the raw data and perform the inverse dynamic analysis,
            I wrote a number of Matlab scripts, the result of which can be seen
            in the figure above. I also developed a simplified model of the
            weight-supported squatting motion, illustrated in the diagram below,
            with which to compare the experimental results.
            </p>
            <img src="images/thesis_model.jpg">
            <div class="caption">
              A simplified model of the weight-supported squat.
            </div>
            <p>
            By running trials at several amounts of weight support and
            comparing the results by means of ANOVA and post-hoc t-tests,
            I found that, as expected, the joint moments decreased relatively
            proportionally with weight support. The more interesting result,
            though, had to do with the kinematics of the squatting motion.
            For most of the squatting motion, the kinematics of the supported
            squat and unsupported squat were similar. However, about 3/4 into
            the rising portion of the squat, the kinematics of the supported
            squat diverged considerably, with the users consistently almost
            "lurching" forward, a fact that was also reflected by the center
            of pressure of the ground reaction force shifting forward.
            </p>
            <p>
            The takeaway was that, while weight support predictably alleviates
            some of the load on the joints during a squat, it can also
            significantly alter the normal, natural motion of the body. The
            true cost of these changes to the body's natural biomechanics is
            unknown&mdash;they may be harmless or they may be detrimental.
            In fact, studies of assistive robotic exoskeletons have found that,
            even though the exoskeletons ostensibly reduce the load on the body,
            they oftentimes increase metabolic cost and oxygen consumption,
            suggesting that the person actually has to work harder with support
            to compensate for the unnatural movement.
            </p>
            <p>
            In other words, seemingly straightforward actions can have
            unforeseen and poorly understood consequences. Any device that affects
            the body's natural biomechanics must be carefully investigated,
            even if it seems, intuitively, like it ought to be purely beneficial.
            </p>
          </div>
        </div>
      </div>

      <div id="suspension-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>
              Analysis of a statically and kinematically indeterminate
              power wheelchair suspension system
            </h3>
          </div>
          <div class="modal-body">
            <p>
            In the power wheelchair industry, the term "mid-wheel drive"
            refers to a class of wheelchairs possessing six wheels, with the
            middle wheels being attached to the drive motors. The weight
            distribution of a power wheelchair (the load borne by each wheel)
            significantly affects its stability and performance, which are
            paramount for both user safety and comfort. The ability to
            analytically model, characterize, and manipulate the weight
            distribution of a power wheelchair can, therefore, be extremely
            valuable.
            </p>
            <p>
            However, a vehicle with six wheels is statically indeterminate,
            meaning that the normal forces of the wheels on the ground cannot
            be calculated. Even if we assume the vehicle and weight
            distribution are symmetric and consider only half the vehicle,
            if the three wheels lie in the same plane, the system is still
            indeterminate. This problem is illustrated below.
            </p>
            <img src="images/suspension_halfcar.png">
            <p>
            The traditional solution to this problem involves incorporating the
            stiffness of the wheels, treating each wheel as a spring. By
            assuming the deflection of each wheel is equal (i.e., the vehicle
            remains level), the normal forces can be computed, as shown below.
            </p>
            <img src="images/suspension_stiffness.png">
            <p>
            In the case of the Quantum Edge 2 mid-wheel drive power wheelchair,
            this approach didn't work&mdash;actual measurements of the weight
            distribution (normal forces) did not match those predicted by this
            simple model, likely due to the complex and nonlinear relationships
            between the components of the suspension. Essentially, the
            suspension components of the different wheels are directly linked.
            This particular system is not only statically indeterminate,
            it's also kinematically indeterminate&mdash;its geometric
            configuration cannot be determined without knowing the normal forces
            (which affect both tire compression and deflection of the suspension
            springs), but the forces cannot be determined without already
            knowing its geometric configuration. It is a Catch-22.
            </p>
            <p>
            To address this, I developed a 5-DOF potential energy model of the
            system in which the compression of each tire, the height of the
            base of the power chair, and the pitch angle of the base were
            allowed to vary. The animation below shows how the compression of
            the springs in the suspension system changes as the height of the
            base is varied (for this simplified demonstration, the compression
            of each tire is held constant, as is the pitch angle of the base).
            </p>
            <img src="images/suspension.gif">
            <p>
            The animation was made in Python with matplotlib. I also used
            Python to compute the potential energy of the system in any given
            configuration (i.e., any given set of values for tire compressions,
            base height above the ground, and base pitch angle). The potential
            energy equation for the system, which takes into account the
            gravitational potential energy of the components of the wheelchair
            and the elastic potential energy due to deflection of the springs
            and tires, is shown below.
            </p>
            <img src="images/suspension_eqn.png">
            <p>
            With the aid of scipy multivariate numerical optimization methods,
            I used this function to find the configuration
            of the system that minimized the potential energy, exploiting the
            fact that a system will tend toward the state in which its
            potential energy is lowest. This principle, which, in physics and
            thermodynamics, is known as the
            <a href="https://en.wikipedia.org/wiki/Minimum_total_potential_energy_principle">
              minimum total potential energy principle</a>, is commonly used
            in solid mechanics to solve finite element structural models. The
            plot below shows how the overall potential energy of the system
            varies with ground clearance, allowing us to determine the ground
            clearance at which potential energy is minimized (for the case
            where the parameters corresponding to the other degrees of freedom
            are held constant).
            </p>
            <img src="images/suspension_energy.png">
            <p>
            My model and solution correctly predicted the ground clearance of
            the actual Quantum Edge 2 power wheelchair with an accuracy of
            &gt;95%, and correctly predicted the normal forces to within 80%
            of the measured values, providing a better understanding of the
            properties of an otherwise obscure suspension mechanism.
            </p>
          </div>
        </div>
      </div>

      <div id="histogram-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Real-time color histogram</h3>
          </div>
          <div class="modal-body">
            <p align="center">
            <iframe width="560" height="315"
              src="https://www.youtube-nocookie.com/embed/iv60xgjGOvg"
              frameborder="0" allow="autoplay; encrypted-media"
              allowfullscreen></iframe>
            </p>
            <p>
            Find the code
            <a href="https://github.com/nrsyed/computer-vision/tree/master/real_time_histogram">
              on Github</a> or read more
              <a href="https://nrsyed.com/2018/02/08/real-time-video-histograms-with-opencv-and-python/">
                on my blog</a>.
            </p>
            <p>
            The video above demonstrates the use of a tool I made in Python
            that, by combining OpenCV and matplotlib, computes and displays
            the three color channel histograms of a video in real time. The
            user can also choose to display the video feed in grayscale and
            display the single grayscale color channel histogram. The number
            of histogram bins can be customized as well.
            </p>
          </div>
        </div>
      </div>

      <div id="actuator-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Design of a linear actuator</h3>
          </div>
          <div class="modal-body">
            <p>
            For part of a larger project at Quantum Rehab, I found myself
            having to design a linear actuator from the ground up, as no
            existing off-the-shelf solutions met the requirements for our
            particular application, which had numerous unconventional space
            restrictions.
            </p>
            <img src="images/actuator_fbd.jpg">
            <p>
            I first familiarized myself with the basic
            principles of leadscrew-based linear motion systems (the free
            body diagram above is a simple visual example of one component of
            this process), and used these principles to derive the equations
            of leadscrew frictional torque specific to our application.
            </p>
            <p>
            Part of designing an ideal linear actuator for the application
            involved selecting a motor whose stall torque and no-load speed
            would allow the actuator to complete its motion in a reasonable
            amount of time. To that end, I developed a set of equations with
            which to compute the optimal motor characteristics for the
            application.
            </p>
            <img src="images/actuator_eqn_force.png">
            <p>
            The equation above permits us to obtain the set of actuator no-load
            speeds (<em>v<sub>NL</sub></em>) and stall loads 
            (<em>F<sub>stall</sub></em>) that would enable an actuator to travel
            its entire stroke length <em>s<sub>max</sub></em> within a time
            <em>T</em>, given a function <em>F(s)</em>, which provides the
            force on the actuator (the force it must overcome) as a function of
            the stroke length <em>s</em> (note that <em>F(s)</em> depends on the
            particular application, and is related to the kinematics and
            dynamics of the system in question). Numerically solving this
            equation for a range of stall loads <em>F<sub>stall</sub></em>
            and plotting the result yields the following curve for a desired
            time <em>T</em> and a hypothetical function <em>F(s)</em>
            (for brevity, <em>F(s)</em> is not shown here):
            </p>
            <img src="images/actuator_nl_stall.jpg" width="60%">
            <p>
            In the figure above, which I created using matplotlib,
            the solid black line represents the set of
            (<em>F<sub>stall</sub></em>, <em>v<sub>NL</sub></em>) values that
            would allow the actuator to travel its full stroke length in time
            <em>T</em>&mdash;in this case, 18 seconds. Actuators with values in
            the green region above the curve would complete the motion faster
            than <em>T</em> and actuators with values in the yellow region
            beneath the curve would complete the motion more slowly than the
            desired time <em>T</em>. An actuator with values in the red region
            would be unable to complete the motion, as the stall load of the
            actuator would be lower than the maximum load that the actuator
            would face over the course of the motion.
            </p>
            <p>
            The same principle can be applied directly to a motor in a
            linear actuator by considering the torque <em>&tau;</em> instead
            of the force (i.e., axial load) <em>F</em>, the angular displacement
            <em>&theta;</em> instead of the stroke (i.e., linear displacement)
            <em>s</em>, and the angular no-load speed <em>&omega;<sub>NL</sub></em>
            instead of the linear no-load speed <em>v<sub>NL</sub></em>:
            </p>
            <img src="images/actuator_eqn_torque.png">
            <p>
            Having developed these equations, I determined how the parameters
            would change at different gear ratios (taking into account how
            inertia is nonlinearly reflected through the leadscrew and gear
            train to the motor), and wrote a Python script to plot curves like
            the one above at different gear ratios <em>N</em>.
            </p>
            <img src="images/actuator_gear_ratios.jpg" width="60%">
            <p>
            This provided a solid guideline for selecting both a motor and
            gearing. In addition to the motor and gearing, my script also
            helped optimize the leadscrew parameters (pitch, lead, lubricant
            friction coefficients, and resultant self-locking ability),
            end fixity to increase the leadscrew critical speed and buckling
            load, and other factors.
            </p>
            <p>
            Ultimately, this analytical approach allowed me to design a
            novel prototype for a new type of linear actuator.
            </p>
          </div>
        </div>
      </div>

      <div id="sort-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Visualizing sorting algorithms</h3>
          </div>
          <div class="modal-body">
            <p align="center">
              <iframe width="560" height="315"
                src="https://www.youtube-nocookie.com/embed/cgNFT4CadL4"
                frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </p>
            <p>
            Find the code on
            <a href="https://github.com/nrsyed/sorts">Github</a> and read
            about the implementation and time complexity of the various sorting
            algorithms on
            <a href="https://nrsyed.com/2018/09/27/visualizing-sorting-algorithms-and-time-complexity-with-matplotlib/">
              my blog</a>.
            </p>
            <p>
            This was a simple project in which I implemented several common
            sorting algorithms and demonstrated, in Python, how to use the
            matplotlib animation module with generator functions to animate
            the algorithms and count the number of operations (swaps,
            comparisons, etc.) required to sort a list of integers.
            </p>
          </div>
        </div>
      </div>

      <div id="gameoflife-modal" class="modal">
        <div class="modal-content">
          <div class="modal-header">
            <span class="close">&times;</span>
            <h3>Interactive and dynamic implementation of Conway's Game of Life</h3>
          </div>
          <div class="modal-body">
            <p align="center">
              <iframe width="560" height="315"
                src="https://www.youtube-nocookie.com/embed/2ihQGeqdovs"
                frameborder="0" allow="accelerometer; autoplay;
                  encrypted-media; gyroscope; picture-in-picture"
                allowfullscreen></iframe>
            </p>
            <p>
              URL: <a href="https://nrsyed.github.io/conway/">
                https://nrsyed.github.io/conway/</a>
              <br>
              Github: <a href="https://github.com/nrsyed/conway">
                https://github.com/nrsyed/conway</a>
            </p>
            <p>
              <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">
                Conway's Game of Life</a> is a well-known "cellular automaton,"
              or "game" in which each cell of a 2D grid can be either alive (on)
              or dead (off). The grid is iteratively updated, with each
              iteration referred to as a generation. The original rules state
              that 1) any living cell with exactly two or three neighbors
              survives to the next generation (otherwise, it dies), and 2) any
              dead cell with exactly three neighbors becomes alive during the
              next generation, as if born by reproduction.
            </p>
            <p>
              I created my own JavaScript implementation of an interactive and
              dynamic version of the Game of Lifedynamic because the rules can
              be changed on the fly, and interactive because the user can change
              them, as well as click cells in the grid to toggle them on and off.
              In my implementation, the user can set a "survival range," where
              a live cell with a number of neighbors within the range survives 
              to the next generation, and a "birth value," which is the number
              of neighbors a dead cell must have to become a live cell during
              the next generation.
            </p>
            <p>
              This can make for some interesting behavior and unique patterns,
              a few examples of which are shown in the video above and in the
              animations below.
            </p>
            <div align="center">
              <img src="images/gameoflife_B1S67.gif">
              <img src="images/gameoflife_random.gif">
            </div>
            <div align="center">
              <img src="images/gameoflife_B3S14.gif">
              <img src="images/gameoflife.gif">
            </div>
          </div>
        </div>
      </div>
    <!-- end #main -->
    </div>
  </body>
  <script src="scripts/template.js"></script>
  <script src="scripts/projects.js"></script>
</html>
